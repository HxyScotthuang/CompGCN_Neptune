{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbStjOS20/nbhuclH6mxjs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mVgnB8Yxhppa","executionInfo":{"status":"ok","timestamp":1678921653858,"user_tz":0,"elapsed":19303,"user":{"displayName":"scott huang","userId":"06489357941762676089"}},"outputId":"65c3b3eb-00c2-4d7f-d739-037be2f1e5b0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import os\n","os.chdir(\"/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune\")"],"metadata":{"id":"xN2qsn71hvya","executionInfo":{"status":"ok","timestamp":1678921670075,"user_tz":0,"elapsed":921,"user":{"displayName":"scott huang","userId":"06489357941762676089"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["%%capture\n","!pip install Cython\n","!pip install ordered_set\n","!pip install --pre -U scikit_learn\n","!pip install torch_scatter"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GhyIaYAQh56H","executionInfo":{"status":"ok","timestamp":1678922802811,"user_tz":0,"elapsed":752170,"user":{"displayName":"scott huang","userId":"06489357941762676089"}},"outputId":"e4a9c8e2-1ede-44ca-e27a-e8fc685de06d"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: Cython in /usr/local/lib/python3.9/dist-packages (0.29.33)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: ordered_set in /usr/local/lib/python3.9/dist-packages (3.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: scikit_learn in /usr/local/lib/python3.9/dist-packages (1.2.2)\n","Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/dist-packages (from scikit_learn) (1.22.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit_learn) (1.1.1)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit_learn) (3.1.0)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit_learn) (1.10.1)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torch_scatter\n","  Downloading torch_scatter-2.1.0.tar.gz (106 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 KB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: torch_scatter\n","  Building wheel for torch_scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torch_scatter: filename=torch_scatter-2.1.0-cp39-cp39-linux_x86_64.whl size=3556607 sha256=1859244ea7d694851361c29f4b4a0a2bdf0a9af43d81ab2bbdd5bbf5d47ddb97\n","  Stored in directory: /root/.cache/pip/wheels/c5/33/3c/b02defb8e41252b9073b3b98433e082a8fb9aa8945127ffcbe\n","Successfully built torch_scatter\n","Installing collected packages: torch_scatter\n","Successfully installed torch_scatter-2.1.0\n"]}]},{"cell_type":"code","source":["%%capture\n","!pip install neptune-client"],"metadata":{"id":"HTXwVl0qmMVm","executionInfo":{"status":"ok","timestamp":1678922836087,"user_tz":0,"elapsed":26754,"user":{"displayName":"scott huang","userId":"06489357941762676089"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["!python run.py -score_func distmult -opn mult -gcn_layer 3 -gpu 0 -data FB15k-237 -name FB \\\n","    -logdir '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/log/' \\\n","    -config '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/config/'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RWWESv_Hh-s7","outputId":"c84a7540-19a3-432b-d2c3-674bb4240b87"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/usr/local/lib/python3.9/dist-packages/neptune/internal/backends/hosted_client.py:48: NeptuneDeprecationWarning: The 'neptune-client' package has been deprecated and will be removed in the future. Install the 'neptune' package instead. For more, see https://docs.neptune.ai/setup/upgrading/\n","  from neptune.version import version as neptune_client_version\n","/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/run.py:6: NeptuneDeprecationWarning: You're importing the Neptune client library via the deprecated `neptune.new` module, which will be removed in a future release. Import directly from `neptune` instead.\n","  import neptune.new as neptune\n","https://app.neptune.ai/R-NBFNet/CMPNN-Rebuttal/e/CMPNNREB-26\n","{'name': 'FB_16_03_2023_00:55:18', 'dataset': 'FB15k-237', 'model': 'compgcn', 'score_func': 'distmult', 'opn': 'mult', 'batch_size': 128, 'gamma': 40.0, 'gpu': '0', 'max_epochs': 500, 'l2': 0.0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 10, 'seed': 41504, 'restore': False, 'bias': False, 'num_bases': -1, 'init_dim': 100, 'gcn_dim': 200, 'embed_dim': None, 'gcn_layer': 3, 'dropout': 0.1, 'hid_drop': 0.3, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 20, 'num_filt': 200, 'ker_sz': 7, 'log_dir': '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/log/', 'config_dir': '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/config/'}\n","/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/run.py:476: NeptuneUnsupportedType: You're attempting to log a type that is not directly supported by Neptune (<class 'NoneType'>).\n","        Convert the value to a supported type, such as a string or float, or use stringify_unsupported(obj)\n","        for dictionaries or collections that contain unsupported values.\n","        For more, see https://docs.neptune.ai/help/value_of_unsupported_type\n","  run[\"params\"] = params\n","2023-03-16 00:55:18,558 - [INFO] - {'name': 'FB_16_03_2023_00:55:18', 'dataset': 'FB15k-237', 'model': 'compgcn', 'score_func': 'distmult', 'opn': 'mult', 'batch_size': 128, 'gamma': 40.0, 'gpu': '0', 'max_epochs': 500, 'l2': 0.0, 'lr': 0.001, 'lbl_smooth': 0.1, 'num_workers': 10, 'seed': 41504, 'restore': False, 'bias': False, 'num_bases': -1, 'init_dim': 100, 'gcn_dim': 200, 'embed_dim': None, 'gcn_layer': 3, 'dropout': 0.1, 'hid_drop': 0.3, 'hid_drop2': 0.3, 'feat_drop': 0.3, 'k_w': 10, 'k_h': 20, 'num_filt': 200, 'ker_sz': 7, 'log_dir': '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/log/', 'config_dir': '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/config/'}\n","{'batch_size': 128,\n"," 'bias': False,\n"," 'config_dir': '/content/drive/MyDrive/Colab '\n","               'Notebooks/partC/CompGCN_Neptune/config/',\n"," 'dataset': 'FB15k-237',\n"," 'dropout': 0.1,\n"," 'embed_dim': None,\n"," 'feat_drop': 0.3,\n"," 'gamma': 40.0,\n"," 'gcn_dim': 200,\n"," 'gcn_layer': 3,\n"," 'gpu': '0',\n"," 'hid_drop': 0.3,\n"," 'hid_drop2': 0.3,\n"," 'init_dim': 100,\n"," 'k_h': 20,\n"," 'k_w': 10,\n"," 'ker_sz': 7,\n"," 'l2': 0.0,\n"," 'lbl_smooth': 0.1,\n"," 'log_dir': '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/log/',\n"," 'lr': 0.001,\n"," 'max_epochs': 500,\n"," 'model': 'compgcn',\n"," 'name': 'FB_16_03_2023_00:55:18',\n"," 'num_bases': -1,\n"," 'num_filt': 200,\n"," 'num_workers': 10,\n"," 'opn': 'mult',\n"," 'restore': False,\n"," 'score_func': 'distmult',\n"," 'seed': 41504}\n","2023-03-16 00:55:24,940 - [INFO] - [E:0| 0]: Train Loss:0.6932,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:27,453 - [INFO] - [E:0| 100]: Train Loss:0.57833,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:29,938 - [INFO] - [E:0| 200]: Train Loss:0.37816,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:32,404 - [INFO] - [E:0| 300]: Train Loss:0.27492,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:34,867 - [INFO] - [E:0| 400]: Train Loss:0.21244,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:37,341 - [INFO] - [E:0| 500]: Train Loss:0.17286,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:39,790 - [INFO] - [E:0| 600]: Train Loss:0.14577,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:42,252 - [INFO] - [E:0| 700]: Train Loss:0.12592,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:44,719 - [INFO] - [E:0| 800]: Train Loss:0.11078,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:47,175 - [INFO] - [E:0| 900]: Train Loss:0.099057,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:49,644 - [INFO] - [E:0| 1000]: Train Loss:0.08953,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:52,105 - [INFO] - [E:0| 1100]: Train Loss:0.081861,  Val MRR:0.0\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:53,864 - [INFO] - [Epoch:0]:  Training Loss:0.07728\n","\n","/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/run.py:321: UserWarning: where received a uint8 condition tensor. This behavior is deprecated and will be removed in a future version of PyTorch. Use a boolean condition instead. (Triggered internally at ../aten/src/ATen/native/TensorCompare.cpp:413.)\n","  pred \t\t\t= torch.where(label.byte(), -torch.ones_like(pred) * 10000000, pred)\n","2023-03-16 00:55:54,285 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:55,518 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:56,478 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:57,706 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:55:58,207 - [INFO] - [Epoch 0 valid]: MRR: Tail : 0.08582, Head : 0.00792, Avg : 0.04687\n","2023-03-16 00:55:58,304 - [INFO] - [Epoch 0]: Training Loss: 0.077279, Valid MRR: 0.04687\n","\n","\n","2023-03-16 00:55:58,798 - [INFO] - [E:1| 0]: Train Loss:0.0032623,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:01,264 - [INFO] - [E:1| 100]: Train Loss:0.0041293,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:03,726 - [INFO] - [E:1| 200]: Train Loss:0.0037479,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:06,201 - [INFO] - [E:1| 300]: Train Loss:0.0035746,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:08,674 - [INFO] - [E:1| 400]: Train Loss:0.0035596,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:11,146 - [INFO] - [E:1| 500]: Train Loss:0.0034976,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:13,624 - [INFO] - [E:1| 600]: Train Loss:0.0034202,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:16,117 - [INFO] - [E:1| 700]: Train Loss:0.003343,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:18,602 - [INFO] - [E:1| 800]: Train Loss:0.0032856,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:21,068 - [INFO] - [E:1| 900]: Train Loss:0.0032521,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:23,551 - [INFO] - [E:1| 1000]: Train Loss:0.0032543,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:26,020 - [INFO] - [E:1| 1100]: Train Loss:0.0032104,  Val MRR:0.04687\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:27,805 - [INFO] - [Epoch:1]:  Training Loss:0.003194\n","\n","2023-03-16 00:56:28,238 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:29,466 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:30,422 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:31,683 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:32,184 - [INFO] - [Epoch 1 valid]: MRR: Tail : 0.14499, Head : 0.02166, Avg : 0.08333\n","2023-03-16 00:56:32,304 - [INFO] - [Epoch 1]: Training Loss: 0.0031943, Valid MRR: 0.08333\n","\n","\n","2023-03-16 00:56:32,751 - [INFO] - [E:2| 0]: Train Loss:0.0023654,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:35,233 - [INFO] - [E:2| 100]: Train Loss:0.0027019,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:37,698 - [INFO] - [E:2| 200]: Train Loss:0.0027155,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:40,173 - [INFO] - [E:2| 300]: Train Loss:0.0026964,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:42,618 - [INFO] - [E:2| 400]: Train Loss:0.0026866,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:45,108 - [INFO] - [E:2| 500]: Train Loss:0.0027191,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:47,600 - [INFO] - [E:2| 600]: Train Loss:0.0027161,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:50,062 - [INFO] - [E:2| 700]: Train Loss:0.0026927,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:52,536 - [INFO] - [E:2| 800]: Train Loss:0.0026895,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:55,009 - [INFO] - [E:2| 900]: Train Loss:0.0026649,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:57,495 - [INFO] - [E:2| 1000]: Train Loss:0.0026491,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:56:59,986 - [INFO] - [E:2| 1100]: Train Loss:0.0026348,  Val MRR:0.08333\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:01,766 - [INFO] - [Epoch:2]:  Training Loss:0.002631\n","\n","2023-03-16 00:57:02,217 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:03,412 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:04,342 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:05,563 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:06,052 - [INFO] - [Epoch 2 valid]: MRR: Tail : 0.16535, Head : 0.0378, Avg : 0.10158\n","2023-03-16 00:57:06,167 - [INFO] - [Epoch 2]: Training Loss: 0.0026305, Valid MRR: 0.10158\n","\n","\n","2023-03-16 00:57:06,652 - [INFO] - [E:3| 0]: Train Loss:0.0023762,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:09,128 - [INFO] - [E:3| 100]: Train Loss:0.0024828,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:11,611 - [INFO] - [E:3| 200]: Train Loss:0.0024813,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:14,093 - [INFO] - [E:3| 300]: Train Loss:0.0025019,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:16,559 - [INFO] - [E:3| 400]: Train Loss:0.0024951,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:19,040 - [INFO] - [E:3| 500]: Train Loss:0.0024895,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:21,515 - [INFO] - [E:3| 600]: Train Loss:0.0024831,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:23,976 - [INFO] - [E:3| 700]: Train Loss:0.0024748,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:26,480 - [INFO] - [E:3| 800]: Train Loss:0.0024587,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:29,002 - [INFO] - [E:3| 900]: Train Loss:0.0024578,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:31,496 - [INFO] - [E:3| 1000]: Train Loss:0.0024496,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:33,965 - [INFO] - [E:3| 1100]: Train Loss:0.0024458,  Val MRR:0.10158\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:35,748 - [INFO] - [Epoch:3]:  Training Loss:0.00244\n","\n","2023-03-16 00:57:36,169 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:37,401 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:38,360 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:39,637 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:40,151 - [INFO] - [Epoch 3 valid]: MRR: Tail : 0.21293, Head : 0.04376, Avg : 0.12834\n","2023-03-16 00:57:40,278 - [INFO] - [Epoch 3]: Training Loss: 0.00244, Valid MRR: 0.12834\n","\n","\n","2023-03-16 00:57:40,757 - [INFO] - [E:4| 0]: Train Loss:0.0021065,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:43,277 - [INFO] - [E:4| 100]: Train Loss:0.0022893,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:45,772 - [INFO] - [E:4| 200]: Train Loss:0.0022953,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:48,272 - [INFO] - [E:4| 300]: Train Loss:0.0023208,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:50,759 - [INFO] - [E:4| 400]: Train Loss:0.0023315,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:53,242 - [INFO] - [E:4| 500]: Train Loss:0.0023353,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:55,736 - [INFO] - [E:4| 600]: Train Loss:0.0023317,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:57:58,224 - [INFO] - [E:4| 700]: Train Loss:0.0023381,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:00,707 - [INFO] - [E:4| 800]: Train Loss:0.0023291,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:03,206 - [INFO] - [E:4| 900]: Train Loss:0.0023238,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:05,691 - [INFO] - [E:4| 1000]: Train Loss:0.0023221,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:08,185 - [INFO] - [E:4| 1100]: Train Loss:0.0023185,  Val MRR:0.12834\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:10,006 - [INFO] - [Epoch:4]:  Training Loss:0.002319\n","\n","2023-03-16 00:58:10,444 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:11,707 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:12,674 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:13,917 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:14,419 - [INFO] - [Epoch 4 valid]: MRR: Tail : 0.23722, Head : 0.0647, Avg : 0.15096\n","2023-03-16 00:58:14,525 - [INFO] - [Epoch 4]: Training Loss: 0.0023187, Valid MRR: 0.15096\n","\n","\n","2023-03-16 00:58:15,004 - [INFO] - [E:5| 0]: Train Loss:0.0020983,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:17,489 - [INFO] - [E:5| 100]: Train Loss:0.0022577,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:19,982 - [INFO] - [E:5| 200]: Train Loss:0.0022377,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:22,464 - [INFO] - [E:5| 300]: Train Loss:0.0022267,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:24,951 - [INFO] - [E:5| 400]: Train Loss:0.0022534,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:27,468 - [INFO] - [E:5| 500]: Train Loss:0.0022323,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:29,955 - [INFO] - [E:5| 600]: Train Loss:0.0022302,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:32,454 - [INFO] - [E:5| 700]: Train Loss:0.0022186,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:34,949 - [INFO] - [E:5| 800]: Train Loss:0.0022169,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:37,454 - [INFO] - [E:5| 900]: Train Loss:0.0022137,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:39,950 - [INFO] - [E:5| 1000]: Train Loss:0.0022069,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:42,442 - [INFO] - [E:5| 1100]: Train Loss:0.0022083,  Val MRR:0.15096\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:44,232 - [INFO] - [Epoch:5]:  Training Loss:0.002208\n","\n","2023-03-16 00:58:44,672 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:45,903 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:46,861 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:48,128 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:48,636 - [INFO] - [Epoch 5 valid]: MRR: Tail : 0.2701, Head : 0.0909, Avg : 0.1805\n","2023-03-16 00:58:48,754 - [INFO] - [Epoch 5]: Training Loss: 0.0022084, Valid MRR: 0.1805\n","\n","\n","2023-03-16 00:58:49,244 - [INFO] - [E:6| 0]: Train Loss:0.0024733,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:51,740 - [INFO] - [E:6| 100]: Train Loss:0.0021112,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:54,243 - [INFO] - [E:6| 200]: Train Loss:0.0021768,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:56,729 - [INFO] - [E:6| 300]: Train Loss:0.0021685,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:58:59,200 - [INFO] - [E:6| 400]: Train Loss:0.0021536,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:01,697 - [INFO] - [E:6| 500]: Train Loss:0.0021521,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:04,210 - [INFO] - [E:6| 600]: Train Loss:0.0021598,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:06,704 - [INFO] - [E:6| 700]: Train Loss:0.0021581,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:09,193 - [INFO] - [E:6| 800]: Train Loss:0.0021472,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:11,692 - [INFO] - [E:6| 900]: Train Loss:0.0021376,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:14,182 - [INFO] - [E:6| 1000]: Train Loss:0.0021355,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:16,691 - [INFO] - [E:6| 1100]: Train Loss:0.0021316,  Val MRR:0.1805\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:18,477 - [INFO] - [Epoch:6]:  Training Loss:0.002131\n","\n","2023-03-16 00:59:18,881 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:20,116 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:21,053 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:22,331 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:22,829 - [INFO] - [Epoch 6 valid]: MRR: Tail : 0.28069, Head : 0.10549, Avg : 0.19309\n","2023-03-16 00:59:22,943 - [INFO] - [Epoch 6]: Training Loss: 0.0021313, Valid MRR: 0.19309\n","\n","\n","2023-03-16 00:59:23,410 - [INFO] - [E:7| 0]: Train Loss:0.0017701,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:25,885 - [INFO] - [E:7| 100]: Train Loss:0.0020925,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:28,367 - [INFO] - [E:7| 200]: Train Loss:0.0021128,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:30,851 - [INFO] - [E:7| 300]: Train Loss:0.0020861,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:33,326 - [INFO] - [E:7| 400]: Train Loss:0.002062,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:35,789 - [INFO] - [E:7| 500]: Train Loss:0.0020665,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:38,254 - [INFO] - [E:7| 600]: Train Loss:0.0020581,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:40,731 - [INFO] - [E:7| 700]: Train Loss:0.0020749,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:43,193 - [INFO] - [E:7| 800]: Train Loss:0.0020643,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:45,675 - [INFO] - [E:7| 900]: Train Loss:0.0020676,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:48,150 - [INFO] - [E:7| 1000]: Train Loss:0.0020616,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:50,658 - [INFO] - [E:7| 1100]: Train Loss:0.0020502,  Val MRR:0.19309\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:52,456 - [INFO] - [Epoch:7]:  Training Loss:0.002048\n","\n","2023-03-16 00:59:52,882 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:54,130 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:55,056 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:56,330 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:56,831 - [INFO] - [Epoch 7 valid]: MRR: Tail : 0.31366, Head : 0.12801, Avg : 0.22084\n","2023-03-16 00:59:56,952 - [INFO] - [Epoch 7]: Training Loss: 0.0020481, Valid MRR: 0.22084\n","\n","\n","2023-03-16 00:59:57,459 - [INFO] - [E:8| 0]: Train Loss:0.0017434,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 00:59:59,914 - [INFO] - [E:8| 100]: Train Loss:0.0020298,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:02,372 - [INFO] - [E:8| 200]: Train Loss:0.0020138,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:04,863 - [INFO] - [E:8| 300]: Train Loss:0.0020285,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:07,327 - [INFO] - [E:8| 400]: Train Loss:0.0020218,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:09,777 - [INFO] - [E:8| 500]: Train Loss:0.0020253,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:12,240 - [INFO] - [E:8| 600]: Train Loss:0.0020226,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:14,693 - [INFO] - [E:8| 700]: Train Loss:0.002014,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:17,142 - [INFO] - [E:8| 800]: Train Loss:0.0020111,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:19,608 - [INFO] - [E:8| 900]: Train Loss:0.0020099,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:22,096 - [INFO] - [E:8| 1000]: Train Loss:0.0020072,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:24,577 - [INFO] - [E:8| 1100]: Train Loss:0.0020008,  Val MRR:0.22084\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:26,362 - [INFO] - [Epoch:8]:  Training Loss:0.001994\n","\n","2023-03-16 01:00:26,793 - [INFO] - [Valid, Tail_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:28,015 - [INFO] - [Valid, Tail_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:28,959 - [INFO] - [Valid, Head_Batch Step 0]\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:30,237 - [INFO] - [Valid, Head_Batch Step 100]\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:30,737 - [INFO] - [Epoch 8 valid]: MRR: Tail : 0.32868, Head : 0.14146, Avg : 0.23507\n","2023-03-16 01:00:30,846 - [INFO] - [Epoch 8]: Training Loss: 0.0019935, Valid MRR: 0.23507\n","\n","\n","2023-03-16 01:00:31,345 - [INFO] - [E:9| 0]: Train Loss:0.010983,  Val MRR:0.23507\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:33,813 - [INFO] - [E:9| 100]: Train Loss:0.0020219,  Val MRR:0.23507\tFB_16_03_2023_00:55:18\n","2023-03-16 01:00:36,310 - [INFO] - [E:9| 200]: Train Loss:0.001998,  Val MRR:0.23507\tFB_16_03_2023_00:55:18\n"]}]},{"cell_type":"code","source":["!python run.py -score_func distmult -opn mult -gcn_layer 3 -gpu 0 -data WN18RR -name WN \\\n","    -logdir '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/log/' \\\n","    -config '/content/drive/MyDrive/Colab Notebooks/partC/CompGCN_Neptune/config/'"],"metadata":{"id":"RAWefPl4km_P"},"execution_count":null,"outputs":[]}]}